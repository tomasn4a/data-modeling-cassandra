{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import Python packages "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import Python packages \n",
    "import csv\n",
    "import glob\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Check current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# Join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    # print(file_path_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/Users/tomas.rojo/Dropbox/Documents/learning/udacity/dend/02_data_modeling/05_project_data_modeling_with_apache_cassandra/cassandra_data_modeling\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Initiate an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# For every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# Read csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # Extract each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# Get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# Print first row\n",
    "print(full_data_rows_list[0])\n",
    "\n",
    "# Create a smaller event data csv file called event_datafile_full csv that will be used to insert data into tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8056\n",
      "['Harmonia', 'Logged In', 'Ryan', 'M', '0', 'Smith', '655.77751', 'free', 'San Jose-Sunnyvale-Santa Clara, CA', 'PUT', 'NextSong', '1.54102E+12', '583', 'Sehr kosmisch', '200', '1.54224E+12', '26']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6821\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating a Cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: I tested this notebook on a local instance of Apache Cassandra, where\n",
    "I had set `authenticator: PasswordAuthenticator` and \n",
    "`authorizer: CassandraAuthorizer` in `cassandra.yaml` in order to gain access \n",
    "to the `cassandra` superuser so that I could create a `student` user. Hence the \n",
    "`PlainTextAuthProvider`.\n",
    "\n",
    "If running on a local version of cassandra, you can connect to your local\n",
    "cluster without needing `auth_provider`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "# Use the student:student toy user\n",
    "auth = PlainTextAuthProvider(username='student', password='student')\n",
    "cluster = Cluster(['127.0.0.1'], auth_provider=auth)\n",
    "\n",
    "# Start session\n",
    "session = cluster.connect()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Keyspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create a Keyspace \n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS sparkifydb\n",
    "        WITH REPLICATION = {\n",
    "            'class': 'SimpleStrategy',\n",
    "            'replication_factor': 1\n",
    "        }\n",
    "    \"\"\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set Keyspace"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Set keyspace\n",
    "try:\n",
    "    session.set_keyspace('sparkifydb')\n",
    "except Exception as e:\n",
    "    print(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Song information for a given sessionId and itemInSession"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Create a table which will return song information by sessionId and itemInSession\n",
    "\n",
    "create_song_by_session_and_item_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS song_by_session_and_item (\n",
    "        sessionId            INT,\n",
    "        itemInSession        INT,\n",
    "        artist               TEXT,\n",
    "        song                 TEXT,\n",
    "        length               FLOAT,\n",
    "        PRIMARY KEY((sessionId, itemInSession))\n",
    "    );\n",
    "\"\"\"      \n",
    "\n",
    "session.execute(create_song_by_session_and_item_table)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f961201b160>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Parse the datafile csv and insert rows into new table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "# Define insert query\n",
    "        query = \"\"\"\n",
    "            INSERT INTO song_by_session_and_item (sessionId, itemInSession, artist, song, length)\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        # Select relevant items from row and insert record\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this first query we want to find some information (artist, song, length)\n",
    "about a song played in a particular `sessionId` and in position `itemInSession`.\n",
    "Both fields used to filter are therefore part of the table's primary key. \n",
    "\n",
    "We chose to go for a composite partition key under the assumption that sessions\n",
    "can vary greatly in length and in order to distribute the data better across the\n",
    "nodes we can use the combination of `sessionId` and `itemInSession`. That being\n",
    "said, the difference in session 'length' might be not that relevant and we could\n",
    "have as well chosen a composite primary key made with `sessionId` as the\n",
    "partition key and `itemInSession` as the clustering key."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## Select song information based on sessionId and itemInSession\n",
    "\n",
    "select_song_by_session_and_item = \"\"\"\n",
    "    SELECT artist, song, length\n",
    "    FROM song_by_session_and_item\n",
    "    WHERE sessionId=(%s) AND itemInSession=(%s);\n",
    "\"\"\"\n",
    "\n",
    "rows = session.execute(select_song_by_session_and_item, (338, 4))\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Row(artist='Faithless', song='Music Matters (Mark Knight Dub)', length=495.30731201171875)\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Songs streamed by a given user in a given session, ordered by itemInSession"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Create a table which will return song information for a given user and session, order by item\n",
    "\n",
    "create_songs_by_user_and_session_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS songs_by_user_and_session (\n",
    "        userId                 INT,\n",
    "        sessionId              INT,\n",
    "        itemInSession          INT,\n",
    "        artist                 TEXT,\n",
    "        song                   TEXT,\n",
    "        first_name             TEXT,\n",
    "        last_name              TEXT,\n",
    "        PRIMARY KEY((userId, sessionId), itemInSession)\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_songs_by_user_and_session_table)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f96136e8f40>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Parse the datafile csv and insert rows into new table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "# Define insert query\n",
    "        query = \"\"\"\n",
    "            INSERT INTO songs_by_user_and_session (userId, sessionId, itemInSession, artist, song, first_name, last_name)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        # Select relevant items from row and insert record\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The second query requires us to return all songs that a particular user streamed\n",
    "in a given session, in the order they were played (captured in `itemInSession`).\n",
    "\n",
    "Our primary key is made up of a composite partition key based on `userId` and\n",
    "`sessionId` and a clustering key based on `itemInSession` to ensure the songs\n",
    "are displayed in the correct order.\n",
    "\n",
    "The reason we chose a composite partition key is that the number of sessions per\n",
    "user varies greatly. Since we want to distribute our data evenly across the\n",
    "cluster we want to avoid very large nodes containing all sessions for a given\n",
    "'super-user'. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Select songs and user name for a given user and sessionId\n",
    "\n",
    "select_songs_by_user_and_session = \"\"\"\n",
    "    SELECT artist, song, first_name, last_name\n",
    "    FROM songs_by_user_and_session\n",
    "    WHERE userId=(%s) AND sessionId=(%s)\n",
    "\"\"\"\n",
    "\n",
    "rows = session.execute(select_songs_by_user_and_session, (10, 182))\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Row(artist='Down To The Bone', song=\"Keep On Keepin' On\", first_name='Sylvie', last_name='Cruz')\n",
      "Row(artist='Three Drives', song='Greece 2000', first_name='Sylvie', last_name='Cruz')\n",
      "Row(artist='Sebastien Tellier', song='Kilometer', first_name='Sylvie', last_name='Cruz')\n",
      "Row(artist='Lonnie Gordon', song='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', first_name='Sylvie', last_name='Cruz')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. List all users that listened to a specific song"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Create a table which will return the users that listened to a specific song\n",
    "\n",
    "create_users_by_song_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users_by_song (\n",
    "        song            TEXT,\n",
    "        userId          INT,\n",
    "        sessionId       INT,\n",
    "        itemInSession   INT,\n",
    "        first_name      TEXT,\n",
    "        last_name       TEXT,\n",
    "        PRIMARY KEY(song, userId)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_users_by_song_table)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f96136d0190>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Parse the datafile csv and insert rows into new table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "# Define insert query\n",
    "        query = \"\"\"\n",
    "            INSERT INTO users_by_song (song, userId, sessionId, itemInSession, first_name, last_name)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        # Select relevant items from row and insert record\n",
    "        session.execute(query, (line[9], int(line[10]), int(line[8]), int(line[3]), line[1], line[4]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this particular query we are going to utilise the fact that in Apache\n",
    "Cassandra all inserts are actually insert/update operations which means that if\n",
    "there is a row with the same primary key that already exists it gets\n",
    "overwritten. This is going to come in quite handy since we only care about\n",
    "whether a user has listened to a given song or not, we don't need to know how\n",
    "many times they have listened to it. So, by using a primary key made up of a\n",
    "composite primary key with `song` as partition key and `userId` as clustering key."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Select all users that have listened to a specific song\n",
    "\n",
    "select_users_by_song = \"\"\"\n",
    "    SELECT first_name, last_name\n",
    "    FROM users_by_song\n",
    "    WHERE song='All Hands Against His Own';\n",
    "\"\"\"\n",
    "\n",
    "rows = session.execute(select_users_by_song)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Row(first_name='Jacqueline', last_name='Lynch')\n",
      "Row(first_name='Tegan', last_name='Levine')\n",
      "Row(first_name='Sara', last_name='Johnson')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop the tables before closing out the sessions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Drop all tables\n",
    "for table in ['song_by_session_and_item', 'songs_by_user_and_session', 'users_by_song']:\n",
    "    session.execute(f'DROP TABLE {table};')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Close the session and cluster connection¶"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Shutdown session and cluster\n",
    "session.shutdown()\n",
    "cluster.shutdown()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('udacity': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "3715e5c520d10b9925e7d43d4b7424d17f68ebd4596487ee8084975c0ee90aa6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}